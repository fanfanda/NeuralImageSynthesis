{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "require 'torch'\n",
    "require 'nn'\n",
    "require 'optim'\n",
    "require 'loadcaffe'\n",
    "require 'hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {caffe_model = '/home/fanfanda/style_transfer/fanfanda_neuralImages/NeuralImageSynthesis/Models/VGG_ILSVRC_19_layers_conv.caffemodel', \n",
    "    input_file = '/home/fanfanda/style_transfer/fanfanda_neuralImages/NeuralImageSynthesis/Tmp/input_sc.hdf5',\n",
    "    init_file = '/home/fanfanda/style_transfer/fanfanda_neuralImages/NeuralImageSynthesis/Tmp/init_sc.hdf5',\n",
    "    gpu = 0, max_iter = 500, print_iter = 50, save_iter = 0, backend = cudnn, \n",
    "    layer_order = 'relu1_1,relu2_1,relu3_1,relu4_1,relu5_1,relu4_2', \n",
    "    output_file = '/home/fanfanda/style_transfer/fanfanda_neuralImages/NeuralImageSynthesis/Tmp/output_sc.hdf5',\n",
    "    mask_file = 'path/to/HDF5file', loss_file = 'path/to/HDF5file'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths.dofile('LossLayers.lua')\n",
    "paths.dofile('Misc.lua')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- Set gpu mode\n",
    "if params.gpu >= 0 then\n",
    "    require 'cutorch'\n",
    "    require 'cunn'\n",
    "    cutorch.setDevice(params.gpu + 1)\n",
    "else\n",
    "    params.backend = 'nn'\n",
    "end\n",
    "if params.backend == 'cudnn' then\n",
    "    require 'cudnn'\n",
    "    if params.cudnn_autotune then\n",
    "        cudnn.benchmark = true\n",
    "    end\n",
    "    cudnn.SpatialConvolution.accGradParameters = nn.SpatialConvolutionMM.accGradParameters -- ie: nop\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Successfully loaded /home/fanfanda/style_transfer/fanfanda_neuralImages/NeuralImageSynthesis/Models/VGG_ILSVRC_19_layers_conv.caffemodel\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv1_1: 64 3 3 3\n",
       "conv1_2: 64 64 3 3\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv2_1: 128 64 3 3\n",
       "conv2_2: 128 128 3 3\n",
       "conv3_1: 256 128 3 3\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv3_2: 256 256 3 3\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv3_3: 256 256 3 3\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv3_4: 256 256 3 3\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv4_1: 512 256 3 3\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv4_2: 512 512 3 3\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv4_3: 512 512 3 3\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv4_4: 512 512 3 3\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv5_1: 512 512 3 3\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv5_2: 512 512 3 3\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv5_3: 512 512 3 3\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv5_4: 512 512 3 3\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- Load network from caffemodel\n",
    "local loadcaffe_backend = params.backend\n",
    "cnn = loadcaffe.load('network', params.caffe_model, params.backend):float()\n",
    "cnn = set_datatype(cnn, params.gpu)\n",
    "\n",
    "-- Load optimisation targets \n",
    "local f = hdf5.open(params.input_file, 'r')\n",
    "opt_targets = f:all()\n",
    "f:close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- Set up new network with appropriate loss layers\n",
    "net = nn.Sequential()\n",
    "loss_modules = {}\n",
    "next_layer_ndx = 1\n",
    "-- Loss layers acting directly on the image\n",
    "if opt_targets['data'] then\n",
    "    loss_modules['data'] = {}\n",
    "    for loss_layer, args in pairs(opt_targets['data']) do\n",
    "        local loss_module = get_loss_module(loss_layer, args)\n",
    "        loss_module = set_datatype(loss_module, params.gpu)\n",
    "        net:add(loss_module)\n",
    "        loss_modules['data'][loss_layer] = loss_module\n",
    "    end\n",
    "    next_layer_ndx = next_layer_ndx + 1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  relu2_1 : \n",
       "    {\n",
       "      GramMSEGuided : \n",
       "        {\n",
       "          targets : DoubleTensor - size: 2x128x128\n",
       "          weights : DoubleTensor - size: 2\n",
       "          guides : DoubleTensor - size: 2x209x314\n",
       "        }\n",
       "    }\n",
       "  relu3_1 : \n",
       "    {\n",
       "      GramMSEGuided : \n",
       "        {\n",
       "          targets : DoubleTensor - size: 2x256x256\n",
       "          weights : DoubleTensor - size: 2\n",
       "          guides : DoubleTensor - size: 2x105x157\n",
       "        }\n",
       "    }\n",
       "  relu1_1 : \n",
       "    {\n",
       "      GramMSEGuided : \n",
       "        {\n",
       "          targets : DoubleTensor - size: 2x64x64\n",
       "          weights : DoubleTensor - size: 2\n",
       "          guides : DoubleTensor - size: 2x418x628\n",
       "        }\n",
       "    }\n",
       "  relu5_1 : \n",
       "    {\n",
       "      GramMSEGuided : \n",
       "        {\n",
       "          targets : DoubleTensor - size: 2x512x512\n",
       "          weights : DoubleTensor - size: 2\n",
       "          guides : DoubleTensor - size: 2x27x40\n",
       "        }\n",
       "    }\n",
       "  relu4_1 : \n",
       "    {\n",
       "      GramMSEGuided : \n",
       "        {\n",
       "          targets : DoubleTensor - size: 2x512x512\n",
       "          weights : DoubleTensor - size: 2\n",
       "          guides : DoubleTensor - size: 2x53x79\n",
       "      "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "  }\n",
       "    }\n",
       "  relu4_2 : \n",
       "    {\n",
       "      MSE : \n",
       "        {\n",
       "          targets : DoubleTensor - size: 1x512x53x79\n",
       "          weights : LongTensor - size: 1\n",
       "        }\n",
       "    }\n",
       "}\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- Loss layers acting on CNN features\n",
    "for i = 1, #cnn do\n",
    "    if next_layer_ndx <= length(opt_targets) then\n",
    "        local layer = cnn:get(i)\n",
    "        local layer_name = layer.name\n",
    "        local layer_type = torch.type(layer)\n",
    "        local is_convolution = (layer_type == 'cudnn.SpatialConvolution' or layer_type == 'nn.SpatialConvolution')\n",
    "        if is_convolution and params.reflectance then\n",
    "            local padW, padH = layer.padW, layer.padH\n",
    "            local pad_layer = nn.SpatialReflectionPadding(padW, padW, padH, padH)\n",
    "            pad_layer = set_datatype(pad_layer, params.gpu)\n",
    "            net:add(pad_layer)\n",
    "            layer.padW = 0\n",
    "            layer.padH = 0\n",
    "        end\n",
    "        net:add(layer)\n",
    "        if opt_targets[layer_name] then\n",
    "            loss_modules[layer_name] = {}\n",
    "            for loss_layer, args in pairs(opt_targets[layer_name]) do\n",
    "                if loss_layer == 'GramMSEDilation' then\n",
    "                    args['conv_layer'] = net.modules[#net.modules-1]\n",
    "                    local dilation_losses = get_loss_module(loss_layer, args)\n",
    "                    for i, dl in ipairs(dilation_losses) do \n",
    "                        dl = set_datatype(dl, params.gpu)\n",
    "                        table.insert(net.modules, #net.modules-1, dl)\n",
    "                    end\n",
    "                    loss_modules[layer_name][loss_layer] = dilation_losses\n",
    "                else\n",
    "                    local loss_module = get_loss_module(loss_layer, args)\n",
    "                    loss_module = set_datatype(loss_module, params.gpu)\n",
    "                    net:add(loss_module)\n",
    "                    loss_modules[layer_name][loss_layer] = loss_module\n",
    "                end\n",
    "            end\n",
    "            next_layer_ndx = next_layer_ndx + 1\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relu2_1\tGramMSEGuided\tnn.GramMSEGuided\n",
       "{\n",
       "  targets : CudaTensor - size: 2x128x128\n",
       "  output : CudaTensor - empty\n",
       "  gram : \n",
       "    {\n",
       "      1 : \n",
       "        nn.Sequential {\n",
       "          [input -> (1) -> (2) -> (3) -> output]\n",
       "          (1): nn.CMulTable\n",
       "          (2): nn.ConcatTable {\n",
       "            input\n",
       "              |`-> (1): nn.View(128, -1)\n",
       "               `-> (2): nn.View(128, -1)\n",
       "               ... -> output\n",
       "          }\n",
       "          (3): nn.MM\n",
       "        }\n",
       "        {\n",
       "          gradInput : table: 0x423bb1f8\n",
       "          modules : \n",
       "            {\n",
       "              1 : \n",
       "                nn.CMulTable\n",
       "                {\n",
       "                  gradInput : table: 0x423bb1f8\n",
       "                  _type : torch.CudaTensor\n",
       "                  output : CudaTensor - empty\n",
       "                }\n",
       "              2 : \n",
       "                nn.ConcatTable {\n",
       "                  input\n",
       "                    |`-> (1): nn.View(128, -1)\n",
       "                     `-> (2): nn.View(128, -1)\n",
       "                     ... -> output\n",
       "                }\n",
       "                {\n",
       "                  gradInput : CudaTensor - empty\n",
       "                  modules : table: 0x423bb328\n",
       "                  _type : torch.CudaTensor\n",
       "                  output : table: 0x423bb350\n",
       "                }\n",
       "              3 : \n",
       "                nn.MM\n",
       "                {\n",
       "                  _type : torch.CudaTensor\n",
       "                  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "output : CudaTensor - empty\n",
       "                  gradInput : table: 0x427123a8\n",
       "                  transA : false\n",
       "                  transB : true\n",
       "                }\n",
       "            }\n",
       "          _type : torch.CudaTensor\n",
       "          output : CudaTensor - empty\n",
       "        }\n",
       "      2 : \n",
       "        nn.Sequential {\n",
       "          [input -> (1) -> (2) -> (3) -> output]\n",
       "          (1): nn.CMulTable\n",
       "          (2): nn.ConcatTable {\n",
       "            input\n",
       "              |`-> (1): nn.View(128, -1)\n",
       "               `-> (2): nn.View(128, -1)\n",
       "               ... -> output\n",
       "          }\n",
       "          (3): nn.MM\n",
       "        }\n",
       "        {\n",
       "          gradInput : table: 0x423bb930\n",
       "          modules : \n",
       "            {\n",
       "              1 : \n",
       "                nn.CMulTable\n",
       "                {\n",
       "                  gradInput : table: 0x423bb930\n",
       "                  _type : torch.CudaTensor\n",
       "                  output : CudaTensor - empty\n",
       "                }\n",
       "              2 : \n",
       "                nn.ConcatTable {\n",
       "                  input\n",
       "                    |`-> (1): nn.View(128, -1)\n",
       "                     `-> (2): nn.View(128, -1)\n",
       "                     ... -> output\n",
       "                }\n",
       "                {\n",
       "                  gradInput : CudaTensor - empty\n",
       "                  modules : table: 0x423bba80\n",
       "                  _type : torch.CudaTensor\n",
       "                  output : table: 0x423bbaa8\n",
       "                }\n",
       "              3 : \n",
       "                nn.MM\n",
       "                {\n",
       "                  _type : torch.CudaTensor\n",
       "                  output : CudaTensor - empty\n",
       "                  gradInput : table: 0x427125b8\n",
       "                  transA : false\n",
       "                  transB : true\n",
       "                }\n",
       "            }\n",
       "    "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "      _type : torch.CudaTensor\n",
       "          output : CudaTensor - empty\n",
       "        }\n",
       "    }\n",
       "  loss : 0\n",
       "  guides : CudaTensor - size: 2x209x314\n",
       "  weights : CudaTensor - size: 2\n",
       "  _type : torch.CudaTensor\n",
       "  G : table: 0x423bbfb8\n",
       "  crit : \n",
       "    nn.MSECriterion\n",
       "    {\n",
       "      gradInput : CudaTensor - empty\n",
       "      sizeAverage : true\n",
       "      output : 0\n",
       "    }\n",
       "  gradInput : CudaTensor - empty\n",
       "}\n",
       "relu5_1\tGramMSEGuided\tnn.GramMSEGuided\n",
       "{\n",
       "  targets : CudaTensor - size: 2x512x512\n",
       "  output : CudaTensor - empty\n",
       "  gram : \n",
       "    {\n",
       "      1 : \n",
       "        nn.Sequential {\n",
       "          [input -> (1) -> (2) -> (3) -> output]\n",
       "          (1): nn.CMulTable\n",
       "          (2): nn.ConcatTable {\n",
       "            input\n",
       "              |`-> (1): nn.View(512, -1)\n",
       "               `-> (2): nn.View(512, -1)\n",
       "               ... -> output\n",
       "          }\n",
       "          (3): nn.MM\n",
       "        }\n",
       "        {\n",
       "          gradInput : table: 0x423c0e70\n",
       "          modules : \n",
       "            {\n",
       "              1 : \n",
       "                nn.CMulTable\n",
       "                {\n",
       "                  gradInput : table: 0x423c0e70\n",
       "                  _type : torch.CudaTensor\n",
       "                  output : CudaTensor - empty\n",
       "                }\n",
       "              2 : \n",
       "                nn.ConcatTable {\n",
       "                  input\n",
       "                    |`-> (1): nn.View(512, -1)\n",
       "                     `-> (2): nn.View(512, -1)\n",
       "                     ... -> output\n",
       "                }\n",
       "                {\n",
       "                  gradInput : CudaTensor - empty\n",
       "                  modules : table: 0x423c0fa0\n",
       "                  _type : torch.CudaTensor\n",
       "                  output : table: 0x423c0fc8\n",
       "                }\n",
       "              3 : \n",
       "                nn.MM\n",
       "                {\n",
       "         "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "         _type : torch.CudaTensor\n",
       "                  output : CudaTensor - empty\n",
       "                  gradInput : table: 0x427136c8\n",
       "                  transA : false\n",
       "                  transB : true\n",
       "                }\n",
       "            }\n",
       "          _type : torch.CudaTensor\n",
       "          output : CudaTensor - empty\n",
       "        }\n",
       "      2 : \n",
       "        nn.Sequential {\n",
       "          [input -> (1) -> (2) -> (3) -> output]\n",
       "          (1): nn.CMulTable\n",
       "          (2): nn.ConcatTable {\n",
       "            input\n",
       "              |`-> (1): nn.View(512, -1)\n",
       "               `-> (2): nn.View(512, -1)\n",
       "               ... -> output\n",
       "          }\n",
       "          (3): nn.MM\n",
       "        }\n",
       "        {\n",
       "          gradInput : table: 0x423c16b8\n",
       "          modules : \n",
       "            {\n",
       "              1 : \n",
       "                nn.CMulTable\n",
       "                {\n",
       "                  gradInput : table: 0x423c16b8\n",
       "                  _type : torch.CudaTensor\n",
       "                  output : CudaTensor - empty\n",
       "                }\n",
       "              2 : \n",
       "                nn.ConcatTable {\n",
       "                  input\n",
       "                    |`-> (1): nn.View(512, -1)\n",
       "                     `-> (2): nn.View(512, -1)\n",
       "                     ... -> output\n",
       "                }\n",
       "                {\n",
       "                  gradInput : CudaTensor - empty\n",
       "                  modules : table: 0x423c17e8\n",
       "                  _type : torch.CudaTensor\n",
       "                  output : table: 0x423c1810\n",
       "                }\n",
       "              3 : \n",
       "                nn.MM\n",
       "                {\n",
       "                  _type : torch.CudaTensor\n",
       "                  output : CudaTensor - empty\n",
       "                  gradInput : table: 0x42714598\n",
       "        "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "          transA : false\n",
       "                  transB : true\n",
       "                }\n",
       "            }\n",
       "          _type : torch.CudaTensor\n",
       "          output : CudaTensor - empty\n",
       "        }\n",
       "    }\n",
       "  loss : 0\n",
       "  guides : CudaTensor - size: 2x27x40\n",
       "  weights : CudaTensor - size: 2\n",
       "  _type : torch.CudaTensor\n",
       "  G : table: 0x423c1d20\n",
       "  crit : \n",
       "    nn.MSECriterion\n",
       "    {\n",
       "      gradInput : CudaTensor - empty\n",
       "      sizeAverage : true\n",
       "      output : 0\n",
       "    }\n",
       "  gradInput : CudaTensor - empty\n",
       "}\n",
       "relu1_1\tGramMSEGuided\tnn.GramMSEGuided\n",
       "{\n",
       "  targets : CudaTensor - size: 2x64x64\n",
       "  output : CudaTensor - empty\n",
       "  gram : \n",
       "    {\n",
       "      1 : \n",
       "        nn.Sequential {\n",
       "          [input -> (1) -> (2) -> (3) -> output]\n",
       "          (1): nn.CMulTable\n",
       "          (2): nn.ConcatTable {\n",
       "            input\n",
       "              |`-> (1): nn.View(64, -1)\n",
       "               `-> (2): nn.View(64, -1)\n",
       "               ... -> output\n",
       "          }\n",
       "          (3): nn.MM\n",
       "        }\n",
       "        {\n",
       "          gradInput : table: 0x423b99a8\n",
       "          modules : \n",
       "            {\n",
       "              1 : \n",
       "                nn.CMulTable\n",
       "                {\n",
       "                  gradInput : table: 0x423b99a8\n",
       "                  _type : torch.CudaTensor\n",
       "                  output : CudaTensor - empty\n",
       "                }\n",
       "              2 : \n",
       "                nn.ConcatTable {\n",
       "                  input\n",
       "                    |`-> (1): nn.View(64, -1)\n",
       "                     `-> (2): nn.View(64, -1)\n",
       "                     ... -> output\n",
       "                }\n",
       "                {\n",
       "                  gradInput : CudaTensor - empty\n",
       "                  modules : table: 0x423b9af8\n",
       "                  _type : torch.CudaTensor\n",
       "                  output : table: 0x423b9b20\n",
       "                }\n",
       "              3 : \n",
       "                nn.MM\n",
       "                {\n",
       "      "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "            _type : torch.CudaTensor\n",
       "                  output : CudaTensor - empty\n",
       "                  gradInput : table: 0x42711f88\n",
       "                  transA : false\n",
       "                  transB : true\n",
       "                }\n",
       "            }\n",
       "          _type : torch.CudaTensor\n",
       "          output : CudaTensor - empty\n",
       "        }\n",
       "      2 : \n",
       "        nn.Sequential {\n",
       "          [input -> (1) -> (2) -> (3) -> output]\n",
       "          (1): nn.CMulTable\n",
       "          (2): nn.ConcatTable {\n",
       "            input\n",
       "              |`-> (1): nn.View(64, -1)\n",
       "               `-> (2): nn.View(64, -1)\n",
       "               ... -> output\n",
       "          }\n",
       "          (3): nn.MM\n",
       "        }\n",
       "        {\n",
       "          gradInput : table: 0x423b9fb8\n",
       "          modules : \n",
       "            {\n",
       "              1 : \n",
       "                nn.CMulTable\n",
       "                {\n",
       "                  gradInput : table: 0x423b9fb8\n",
       "                  _type : torch.CudaTensor\n",
       "                  output : CudaTensor - empty\n",
       "                }\n",
       "              2 : \n",
       "                nn.ConcatTable {\n",
       "                  input\n",
       "                    |`-> (1): nn.View(64, -1)\n",
       "                     `-> (2): nn.View(64, -1)\n",
       "                     ... -> output\n",
       "                }\n",
       "                {\n",
       "                  gradInput : CudaTensor - empty\n",
       "                  modules : table: 0x423ba108\n",
       "                  _type : torch.CudaTensor\n",
       "                  output : table: 0x423ba130\n",
       "                }\n",
       "              3 : \n",
       "                nn.MM\n",
       "                {\n",
       "                  _type : torch.CudaTensor\n",
       "                  output : CudaTensor - empty\n",
       "                  gradInput : table: 0x42712198\n",
       "                  transA : false\n",
       "                  transB : true\n",
       "                }\n",
       "            "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "}\n",
       "          _type : torch.CudaTensor\n",
       "          output : CudaTensor - empty\n",
       "        }\n",
       "    }\n",
       "  loss : 0\n",
       "  guides : CudaTensor - size: 2x418x628\n",
       "  weights : CudaTensor - size: 2\n",
       "  _type : torch.CudaTensor\n",
       "  G : table: 0x423ba3e8\n",
       "  crit : \n",
       "    nn.MSECriterion\n",
       "    {\n",
       "      gradInput : CudaTensor - empty\n",
       "      sizeAverage : true\n",
       "      output : 0\n",
       "    }\n",
       "  gradInput : CudaTensor - empty\n",
       "}\n",
       "relu4_2\tMSE\tnn.MSE\n",
       "{\n",
       "  targets : CudaTensor - size: 1x512x53x79\n",
       "  _type : torch.CudaTensor\n",
       "  output : CudaTensor - empty\n",
       "  gradInput : CudaTensor - empty\n",
       "  loss : 0\n",
       "  crit : \n",
       "    nn.MSECriterion\n",
       "    {\n",
       "      gradInput : CudaTensor - empty\n",
       "      sizeAverage : true\n",
       "      output : 0\n",
       "    }\n",
       "  weights : CudaTensor - size: 1\n",
       "}\n",
       "relu4_1\tGramMSEGuided\tnn.GramMSEGuided\n",
       "{\n",
       "  targets : CudaTensor - size: 2x512x512\n",
       "  output : CudaTensor - empty\n",
       "  gram : \n",
       "    {\n",
       "      1 : \n",
       "        nn.Sequential {\n",
       "          [input -> (1) -> (2) -> (3) -> output]\n",
       "          (1): nn.CMulTable\n",
       "          (2): nn.ConcatTable {\n",
       "            input\n",
       "              |`-> (1): nn.View(512, -1)\n",
       "               `-> (2): nn.View(512, -1)\n",
       "               ... -> output\n",
       "          }\n",
       "          (3): nn.MM\n",
       "        }\n",
       "        {\n",
       "          gradInput : table: 0x423beb00\n",
       "          modules : \n",
       "            {\n",
       "              1 : \n",
       "                nn.CMulTable\n",
       "                {\n",
       "                  gradInput : table: 0x423beb00\n",
       "                  _type : torch.CudaTensor\n",
       "                  output : CudaTensor - empty\n",
       "                }\n",
       "              2 : \n",
       "                nn.ConcatTable {\n",
       "                  input\n",
       "                    |`-> (1): nn.View(512, -1)\n",
       "                     `-> (2): nn.View(512, -1)\n",
       "                     ... -> output\n",
       "                }\n",
       "                {\n",
       "                  gradInput : CudaTensor - empty\n",
       "                  modules : table: 0x423bec30\n",
       "                  _type : torch.CudaTensor\n",
       "                  output : table: 0x423bec58\n",
       "       "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "         }\n",
       "              3 : \n",
       "                nn.MM\n",
       "                {\n",
       "                  _type : torch.CudaTensor\n",
       "                  output : CudaTensor - empty\n",
       "                  gradInput : table: 0x42713358\n",
       "                  transA : false\n",
       "                  transB : true\n",
       "                }\n",
       "            }\n",
       "          _type : torch.CudaTensor\n",
       "          output : CudaTensor - empty\n",
       "        }\n",
       "      2 : \n",
       "        nn.Sequential {\n",
       "          [input -> (1) -> (2) -> (3) -> output]\n",
       "          (1): nn.CMulTable\n",
       "          (2): nn.ConcatTable {\n",
       "            input\n",
       "              |`-> (1): nn.View(512, -1)\n",
       "               `-> (2): nn.View(512, -1)\n",
       "               ... -> output\n",
       "          }\n",
       "          (3): nn.MM\n",
       "        }\n",
       "        {\n",
       "          gradInput : table: 0x423bf348\n",
       "          modules : \n",
       "            {\n",
       "              1 : \n",
       "                nn.CMulTable\n",
       "                {\n",
       "                  gradInput : table: 0x423bf348\n",
       "                  _type : torch.CudaTensor\n",
       "                  output : CudaTensor - empty\n",
       "                }\n",
       "              2 : \n",
       "                nn.ConcatTable {\n",
       "                  input\n",
       "                    |`-> (1): nn.View(512, -1)\n",
       "                     `-> (2): nn.View(512, -1)\n",
       "                     ... -> output\n",
       "                }\n",
       "                {\n",
       "                  gradInput : CudaTensor - empty\n",
       "                  modules : table: 0x423bf498\n",
       "                  _type : torch.CudaTensor\n",
       "                  output : table: 0x423bf4c0\n",
       "                }\n",
       "              3 : \n",
       "                nn.MM\n",
       "                {\n",
       "                  _type : torch.CudaTensor\n",
       "       "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "           output : CudaTensor - empty\n",
       "                  gradInput : table: 0x42713568\n",
       "                  transA : false\n",
       "                  transB : true\n",
       "                }\n",
       "            }\n",
       "          _type : torch.CudaTensor\n",
       "          output : CudaTensor - empty\n",
       "        }\n",
       "    }\n",
       "  loss : 0\n",
       "  guides : CudaTensor - size: 2x53x79\n",
       "  weights : CudaTensor - size: 2\n",
       "  _type : torch.CudaTensor\n",
       "  G : table: 0x423bf988\n",
       "  crit : \n",
       "    nn.MSECriterion\n",
       "    {\n",
       "      gradInput : CudaTensor - empty\n",
       "      sizeAverage : true\n",
       "      output : 0\n",
       "    }\n",
       "  gradInput : CudaTensor - empty\n",
       "}\n",
       "relu3_1\tGramMSEGuided\tnn.GramMSEGuided\n",
       "{\n",
       "  targets : CudaTensor - size: 2x256x256\n",
       "  output : CudaTensor - empty\n",
       "  gram : \n",
       "    {\n",
       "      1 : \n",
       "        nn.Sequential {\n",
       "          [input -> (1) -> (2) -> (3) -> output]\n",
       "          (1): nn.CMulTable\n",
       "          (2): nn.ConcatTable {\n",
       "            input\n",
       "              |`-> (1): nn.View(256, -1)\n",
       "               `-> (2): nn.View(256, -1)\n",
       "               ... -> output\n",
       "          }\n",
       "          (3): nn.MM\n",
       "        }\n",
       "        {\n",
       "          gradInput : table: 0x423bcdf8\n",
       "          modules : \n",
       "            {\n",
       "              1 : \n",
       "                nn.CMulTable\n",
       "                {\n",
       "                  gradInput : table: 0x423bcdf8\n",
       "                  _type : torch.CudaTensor\n",
       "                  output : CudaTensor - empty\n",
       "                }\n",
       "              2 : \n",
       "                nn.ConcatTable {\n",
       "                  input\n",
       "                    |`-> (1): nn.View(256, -1)\n",
       "                     `-> (2): nn.View(256, -1)\n",
       "                     ... -> output\n",
       "                }\n",
       "                {\n",
       "                  gradInput : CudaTensor - empty\n",
       "                  modules : table: 0x423bcf28\n",
       "                  _type : torch.CudaTensor\n",
       "                  output : table: 0x423bcf50"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "                }\n",
       "              3 : \n",
       "                nn.MM\n",
       "                {\n",
       "                  _type : torch.CudaTensor\n",
       "                  output : CudaTensor - empty\n",
       "                  gradInput : table: 0x42712f38\n",
       "                  transA : false\n",
       "                  transB : true\n",
       "                }\n",
       "            }\n",
       "          _type : torch.CudaTensor\n",
       "          output : CudaTensor - empty\n",
       "        }\n",
       "      2 : \n",
       "        nn.Sequential {\n",
       "          [input -> (1) -> (2) -> (3) -> output]\n",
       "          (1): nn.CMulTable\n",
       "          (2): nn.ConcatTable {\n",
       "            input\n",
       "              |`-> (1): nn.View(256, -1)\n",
       "               `-> (2): nn.View(256, -1)\n",
       "               ... -> output\n",
       "          }\n",
       "          (3): nn.MM\n",
       "        }\n",
       "        {\n",
       "          gradInput : table: 0x423bd618\n",
       "          modules : \n",
       "            {\n",
       "              1 : \n",
       "                nn.CMulTable\n",
       "                {\n",
       "                  gradInput : table: 0x423bd618\n",
       "                  _type : torch.CudaTensor\n",
       "                  output : CudaTensor - empty\n",
       "                }\n",
       "              2 : \n",
       "                nn.ConcatTable {\n",
       "                  input\n",
       "                    |`-> (1): nn.View(256, -1)\n",
       "                     `-> (2): nn.View(256, -1)\n",
       "                     ... -> output\n",
       "                }\n",
       "                {\n",
       "                  gradInput : CudaTensor - empty\n",
       "                  modules : table: 0x423bd768\n",
       "                  _type : torch.CudaTensor\n",
       "                  output : table: 0x423bd790\n",
       "                }\n",
       "              3 : \n",
       "                nn.MM\n",
       "                {\n",
       "            "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for layer_name, layer_table in pairs(loss_modules) do\n",
    "    for loss_layer, loss_module in pairs(layer_table) do\n",
    "        print(layer_name, loss_layer, loss_module)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- Get flat list of loss modules to call in feval\n",
    "loss_modules_flat = {}\n",
    "for layer_name, layer_table in pairs(loss_modules) do\n",
    "    for loss_layer, loss_module in pairs(layer_table) do\n",
    "        if loss_layer == 'GramMSEDilation' then\n",
    "            for _, dilation_module in pairs(loss_module) do\n",
    "                loss_modules_flat[#loss_modules_flat + 1] = dilation_module\n",
    "            end\n",
    "        else\n",
    "            loss_modules_flat[#loss_modules_flat + 1] = loss_module\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- We don't need the base CNN anymore, so clean it up to save memory.\n",
    "cnn = nil\n",
    "for i=1, #net.modules do\n",
    "    local module = net.modules[i]\n",
    "    if torch.type(module) == 'nn.SpatialConvolutionMM' then\n",
    "        print('Clear', i)\n",
    "        module.gradWeight = nil\n",
    "        module.gradBias = nil\n",
    "    end\n",
    "end\n",
    "collectgarbage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- Load initialisation \n",
    "local f = hdf5.open(params.init_file, 'r')\n",
    "img = f:all()['init']\n",
    "f:close()\n",
    "img = set_datatype(img, params.gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- Load mask if specified\n",
    "mask = nil\n",
    "if params.mask_file ~= 'path/to/HDF5file' then\n",
    "    local f = hdf5.open(params.mask_file, 'r')\n",
    "    mask = f:all()['mask']\n",
    "    f:close()\n",
    "    mask = set_datatype(mask, params.gpu)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- Run it through the network once to get the proper size for the gradient\n",
    "-- All the gradients will come from the extra loss modules, so we just pass\n",
    "-- zeros into the top of the net on the backward pass.\n",
    "y = net:forward(img)\n",
    "dy = img.new(#y):zero()\n",
    "\n",
    "-- Declare optimisation options\n",
    "optim_state = {\n",
    "  maxIter = params.max_iter,\n",
    "  verbose = true,\n",
    "  tolX = 0,\n",
    "  tolFun = 0,\n",
    "}\n",
    "\n",
    "-- Get layer_order for use in maybe_print\n",
    "layer_order = params.layer_order:split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- Function to evaluate loss and gradient. We run the net forward and\n",
    "-- backward to get the gradient, and sum up losses from the loss modules.\n",
    "-- optim.lbfgs internally handles iteration and calls this fucntion many\n",
    "-- times, so we manually count the number of iterations to handle printing\n",
    "-- and saving intermediate results.\n",
    "num_calls = 0\n",
    "function feval(x)\n",
    "    num_calls = num_calls + 1\n",
    "    net:forward(x)\n",
    "    local grad = net:updateGradInput(x, dy)\n",
    "    local loss = 0\n",
    "    for _, mod in ipairs(loss_modules_flat) do\n",
    "        loss = loss + mod.loss\n",
    "    end\n",
    "    maybe_print(num_calls, params.print_iter, params.max_iter, layer_order, loss_modules, loss)\n",
    "    maybe_save(num_calls, params.save_iter, params.max_iter, params.output_file, img)\n",
    "\n",
    "    if mask then\n",
    "        grad[mask:repeatTensor(1,1,1):expandAs(grad)] = 0\n",
    "    end\n",
    "\n",
    "    collectgarbage()\n",
    "    -- optim.lbfgs expects a vector for gradients\n",
    "    return loss, grad:view(grad:nElement())\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Running optimization with L-BFGS\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<optim.lbfgs> \tcreating recyclable direction/step/history buffers\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Iteration 50 / 500\t\n",
       "relu1_1\t\n",
       "GramMSEGuided loss: 347367.065430\t\n",
       "relu2_1\t\n",
       "GramMSEGuided loss: 1860508.850098\t\n",
       "relu3_1\t\n",
       "GramMSEGuided loss: 535573.730469\t\n",
       "relu4_1\t\n",
       "GramMSEGuided loss: 2280119.964600\t\n",
       "relu5_1\t\n",
       "GramMSEGuided loss: 7122.635245\t\n",
       "relu4_2\t\n",
       "MSE loss: 363061.937500\t\n",
       "Total loss: 5393754.183341\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Iteration 100 / 500\t\n",
       "relu1_1\t\n",
       "GramMSEGuided loss: 241166.229248\t\n",
       "relu2_1\t\n",
       "GramMSEGuided loss: 883048.004150\t\n",
       "relu3_1\t\n",
       "GramMSEGuided loss: 223984.634399\t\n",
       "relu4_1\t\n",
       "GramMSEGuided loss: 850371.139526\t\n",
       "relu5_1\t\n",
       "GramMSEGuided loss: 5656.172872\t\n",
       "relu4_2\t\n",
       "MSE loss: 410252.281250\t\n",
       "Total loss: 2614478.461446\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Iteration 150 / 500\t\n",
       "relu1_1\t\n",
       "GramMSEGuided loss: 149447.742462\t\n",
       "relu2_1\t\n",
       "GramMSEGuided loss: 447449.279785\t\n",
       "relu3_1\t\n",
       "GramMSEGuided loss: 113262.180328\t\n",
       "relu4_1\t\n",
       "GramMSEGuided loss: 506814.430237\t\n",
       "relu5_1\t\n",
       "GramMSEGuided loss: 5160.824716\t\n",
       "relu4_2\t\n",
       "MSE loss: 419243.093750\t\n",
       "Total loss: 1641377.551279\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Iteration 200 / 500\t\n",
       "relu1_1\t\n",
       "GramMSEGuided loss: 84751.714706\t\n",
       "relu2_1\t\n",
       "GramMSEGuided loss: 259409.706116\t\n",
       "relu3_1\t\n",
       "GramMSEGuided loss: 69491.338730\t\n",
       "relu4_1\t\n",
       "GramMSEGuided loss: 347352.264404\t\n",
       "relu5_1\t\n",
       "GramMSEGuided loss: 4780.114174\t\n",
       "relu4_2\t\n",
       "MSE loss: 416534.187500\t\n",
       "Total loss: 1182319.325630\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Iteration 250 / 500\t\n",
       "relu1_1\t\n",
       "GramMSEGuided loss: 45331.935883\t\n",
       "relu2_1\t\n",
       "GramMSEGuided loss: 158746.646881\t\n",
       "relu3_1\t\n",
       "GramMSEGuided loss: 50741.531372\t\n",
       "relu4_1\t\n",
       "GramMSEGuided loss: 273547.294617\t\n",
       "relu5_1\t\n",
       "GramMSEGuided loss: 4548.034191\t\n",
       "relu4_2\t\n",
       "MSE loss: 408806.312500\t\n",
       "Total loss: 941721.755444\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Iteration 300 / 500\t\n",
       "relu1_1\t\n",
       "GramMSEGuided loss: 24585.073471\t\n",
       "relu2_1\t\n",
       "GramMSEGuided loss: 94761.217117\t\n",
       "relu3_1\t\n",
       "GramMSEGuided loss: 40132.244110\t\n",
       "relu4_1\t\n",
       "GramMSEGuided loss: 225896.289825\t\n",
       "relu5_1\t\n",
       "GramMSEGuided loss: 4354.886055\t\n",
       "relu4_2\t\n",
       "MSE loss: 400543.250000\t\n",
       "Total loss: 790272.960579\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Iteration 350 / 500\t\n",
       "relu1_1\t\n",
       "GramMSEGuided loss: 14814.221859\t\n",
       "relu2_1\t\n",
       "GramMSEGuided loss: 60099.045753\t\n",
       "relu3_1\t\n",
       "GramMSEGuided loss: 34208.135605\t\n",
       "relu4_1\t\n",
       "GramMSEGuided loss: 193672.176361\t\n",
       "relu5_1\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GramMSEGuided loss: 4250.925601\t\n",
       "relu4_2\t\n",
       "MSE loss: 391413.906250\t\n",
       "Total loss: 698458.411429\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Iteration 400 / 500\t\n",
       "relu1_1\t\n",
       "GramMSEGuided loss: 10582.937241\t\n",
       "relu2_1\t\n",
       "GramMSEGuided loss: 42681.144714\t\n",
       "relu3_1\t\n",
       "GramMSEGuided loss: 29578.643799\t\n",
       "relu4_1\t\n",
       "GramMSEGuided loss: 171818.328857\t\n",
       "relu5_1\t\n",
       "GramMSEGuided loss: 4166.787565\t\n",
       "relu4_2\t\n",
       "MSE loss: 383988.937500\t\n",
       "Total loss: 642816.779676\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Iteration 450 / 500\t\n",
       "relu1_1\t\n",
       "GramMSEGuided loss: 8798.457086\t\n",
       "relu2_1\t\n",
       "GramMSEGuided loss: 32912.680626\t\n",
       "relu3_1\t\n",
       "GramMSEGuided loss: 25892.885208\t\n",
       "relu4_1\t\n",
       "GramMSEGuided loss: 155953.596115\t\n",
       "relu5_1\t\n",
       "GramMSEGuided loss: 4103.775382\t\n",
       "relu4_2\t\n",
       "MSE loss: 376364.531250\t\n",
       "Total loss: 604025.925667\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Iteration 500 / 500\t\n",
       "relu1_1\t\n",
       "GramMSEGuided loss: 7334.957600\t\n",
       "relu2_1\t\n",
       "GramMSEGuided loss: 25784.390926\t\n",
       "relu3_1\t\n",
       "GramMSEGuided loss: 22997.954369\t\n",
       "relu4_1\t\n",
       "GramMSEGuided loss: 143399.906158\t\n",
       "relu5_1\t\n",
       "GramMSEGuided loss: 4046.746254\t\n",
       "relu4_2\t\n",
       "MSE loss: 370113.593750\t\n",
       "Total loss: 573677.549057\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<optim.lbfgs> \treached max number of iterations\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " -- Run optimization.\n",
    "print('Running optimization with L-BFGS')\n",
    "local x, losses = optim.lbfgs(feval, img, optim_state)\n",
    "\n",
    "-- Also save result if optimisation stops before max iter is reached\n",
    "if num_calls < params.max_iter then\n",
    "    maybe_save(params.max_iter, params.save_iter, params.max_iter, params.output_file, img)\n",
    "end\n",
    "\n",
    "-- Optionally save the loss as tracked over the optimisation\n",
    "if params.loss_file ~= 'path/to/HDF5file' then\n",
    "    local f = hdf5.open(params.loss_file, 'w')\n",
    "    f:write('losses', torch.Tensor(losses):double())\n",
    "    f:close()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\t\n",
       "\u001b[1;35mlbfgs(opfunc, x[, config][, state])\u001b[0m\n",
       "\n",
       "\n",
       "An implementation of \u001b[1;30mL-BFGS\u001b[0m that relies on a user-provided line search \n",
       "function (\u001b[0;32m state.lineSearch \u001b[0m).\n",
       "If this function is not provided, then a simple learning rate is used \n",
       "to produce fixed size steps.\n",
       "Fixed size steps are much less costly than line searches, and can be useful \n",
       "for stochastic problems.\n",
       "\n",
       "The learning rate is used even when a line search is provided.\n",
       "This is also useful for large-scale stochastic problems, where opfunc \n",
       "is a noisy approximation of\u001b[0;32m f(x) \u001b[0m.\n",
       "In that case, the learning rate allows a reduction of confidence in the \n",
       "step size.\n",
       "\n",
       "Arguments:\n",
       "\n",
       "\u001b[0;34m> \u001b[0m\u001b[0;32m opfunc \u001b[0m: a function that takes a single input\u001b[0;32m X \u001b[0m, the point of \n",
       "evaluation, and returns\u001b[0;32m f(X) \u001b[0mand\u001b[0;32m df/dX \u001b[0m\u001b[0;34m> \u001b[0m\u001b[0;32m x \u001b[0m: the initial point\n",
       "\u001b[0;34m> \u001b[0m\u001b[0;32m config \u001b[0m: a table with configuration parameters for the optimizer\n",
       "\u001b[0;34m> \u001b[0m\u001b[0;32m config.maxIter \u001b[0m: Maximum number of iterations allowed\n",
       "\u001b[0;34m> \u001b[0m\u001b[0;32m config.maxEval \u001b[0m: Maximum number of function evaluations\n",
       "\u001b[0;34m> \u001b[0m\u001b[0;32m config.tolFun \u001b[0m: Termination tolerance on the first-order optimality\n",
       "\u001b[0;34m> \u001b[0m\u001b[0;32m config.tolX \u001b[0m: Termination tol on progress in terms of func/param \n",
       "changes\n",
       "\u001b[0;34m> \u001b[0m\u001b[0;32m config.lineSearch \u001b[0m: A line search function\n",
       "\u001b[0;34m> \u001b[0m\u001b[0;32m config.learningRate \u001b[0m: If no line search provided, then a fixed \n",
       "step size is used\n",
       "\n",
       "\n",
       "Returns:\n",
       "\n",
       "\u001b[0;34m> \u001b[0m\u001b[0;32m x* \u001b[0m: the new\u001b[0;32m x \u001b[0mvector, at the optimal point\n",
       "\u001b[0;34m> \u001b[0m\u001b[0;32m f \u001b[0m: a table of all function values:\n",
       "<ul>\n",
       "<li>\u001b[0;32m f[1] \u001b[0mis the value of the function before any optimization and\n",
       "\u001b[0;34m> \u001b[0m\u001b[0;32m f[#f] \u001b[0mis the final fully optimized value, at\u001b[0;32m x* \u001b[0m</li>\n",
       "</ul>\t\n",
       "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\t\n",
       "\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?optim.lbfgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
