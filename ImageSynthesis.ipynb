{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "require 'torch'\n",
    "require 'nn'\n",
    "require 'optim'\n",
    "require 'loadcaffe'\n",
    "require 'hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {gpu = 0,backend = 'cudnn', \n",
    "    caffe_model = '/home/fanfanda/style_transfer/fanfanda_neuralImages/NeuralImageSynthesis/Models/VGG_ILSVRC_19_layers_conv.caffemodel', \n",
    "    input_file = '/home/fanfanda/style_transfer/fanfanda_neuralImages/NeuralImageSynthesis/Tmp/input.hdf5', \n",
    "    init_file = '/home/fanfanda/style_transfer/fanfanda_neuralImages/NeuralImageSynthesis/Tmp/init.hdf5',\n",
    "    max_iter = 50, print_iter = 50, save_iter = 0, layer_order = 'relu1_1,relu2_1,relu3_1,relu4_1,relu5_1,relu4_2',\n",
    "    output_file = '/home/fanfanda/style_transfer/fanfanda_neuralImages/NeuralImageSynthesis/Tmp/output.hdf', \n",
    "    mask_file = 'path/to/HDF5file', loss_file = 'path/to/HDF5file'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths.dofile('LossLayers.lua')\n",
    "paths.dofile('Misc.lua')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- Set gpu mode\n",
    "if params.gpu >= 0 then\n",
    "    require 'cutorch'\n",
    "    require 'cunn'\n",
    "    cutorch.setDevice(params.gpu + 1)\n",
    "else\n",
    "    params.backend = 'nn'\n",
    "end\n",
    "if params.backend == 'cudnn' then\n",
    "    require 'cudnn'\n",
    "    if params.cudnn_autotune then\n",
    "        cudnn.benchmark = true\n",
    "    end\n",
    "    cudnn.SpatialConvolution.accGradParameters = nn.SpatialConvolutionMM.accGradParameters -- ie: nop\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Successfully loaded /home/fanfanda/style_transfer/fanfanda_neuralImages/NeuralImageSynthesis/Models/VGG_ILSVRC_19_layers_conv.caffemodel\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv1_1: 64 3 3 3\n",
       "conv1_2: 64 64 3 3\n",
       "conv2_1: 128 64 3 3\n",
       "conv2_2: 128 128 3 3\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv3_1: 256 128 3 3\n",
       "conv3_2: 256 256 3 3\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv3_3: 256 256 3 3\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv3_4: 256 256 3 3\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv4_1: 512 256 3 3\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv4_2: 512 512 3 3\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv4_3: 512 512 3 3\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv4_4: 512 512 3 3\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv5_1: 512 512 3 3\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv5_2: 512 512 3 3\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv5_3: 512 512 3 3\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv5_4: 512 512 3 3\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- Load network from caffemodel\n",
    "local loadcaffe_backend = params.backend\n",
    "cnn = loadcaffe.load('network', params.caffe_model, params.backend):float()\n",
    "cnn = set_datatype(cnn, params.gpu)\n",
    "\n",
    "-- Load optimisation targets \n",
    "local f = hdf5.open(params.input_file, 'r')\n",
    "opt_targets = f:all()\n",
    "f:close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  relu2_1 : \n",
       "    {\n",
       "      GramMSE : \n",
       "        {\n",
       "          targets : DoubleTensor - size: 1x128x128\n",
       "          weights : DoubleTensor - size: 1\n",
       "        }\n",
       "    }\n",
       "  relu3_1 : \n",
       "    {\n",
       "      GramMSE : \n",
       "        {\n",
       "          targets : DoubleTensor - size: 1x256x256\n",
       "          weights : DoubleTensor - size: 1\n",
       "        }\n",
       "    }\n",
       "  relu1_1 : \n",
       "    {\n",
       "      GramMSE : \n",
       "        {\n",
       "          targets : DoubleTensor - size: 1x64x64\n",
       "          weights : DoubleTensor - size: 1\n",
       "        }\n",
       "    }\n",
       "  relu5_1 : \n",
       "    {\n",
       "      GramMSE : \n",
       "        {\n",
       "          targets : DoubleTensor - size: 1x512x512\n",
       "          weights : DoubleTensor - size: 1\n",
       "        }\n",
       "    }\n",
       "  relu4_1 : \n",
       "    {\n",
       "      GramMSE : \n",
       "        {\n",
       "          targets : DoubleTensor - size: 1x512x512\n",
       "          weights : DoubleTensor - size: 1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "        }\n",
       "    }\n",
       "  relu4_2 : \n",
       "    {\n",
       "      MSE : \n",
       "        {\n",
       "          targets : DoubleTensor - size: 1x512x56x74\n",
       "          weights : LongTensor - size: 1\n",
       "        }\n",
       "    }\n",
       "}\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- Set up new network with appropriate loss layers\n",
    "net = nn.Sequential()\n",
    "loss_modules = {}\n",
    "next_layer_ndx = 1\n",
    "-- Loss layers acting directly on the image\n",
    "if opt_targets['data'] then\n",
    "    loss_modules['data'] = {}\n",
    "    for loss_layer, args in pairs(opt_targets['data']) do\n",
    "        local loss_module = get_loss_module(loss_layer, args)\n",
    "        loss_module = set_datatype(loss_module, params.gpu)\n",
    "        net:add(loss_module)\n",
    "        loss_modules['data'][loss_layer] = loss_module\n",
    "    end\n",
    "    next_layer_ndx = next_layer_ndx + 1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- Loss layers acting on CNN features\n",
    "for i = 1, #cnn do\n",
    "    if next_layer_ndx <= length(opt_targets) then\n",
    "        local layer = cnn:get(i)\n",
    "        local layer_name = layer.name\n",
    "        local layer_type = torch.type(layer)\n",
    "        local is_convolution = (layer_type == 'cudnn.SpatialConvolution' or layer_type == 'nn.SpatialConvolution')\n",
    "        if is_convolution and params.reflectance then\n",
    "            local padW, padH = layer.padW, layer.padH\n",
    "            local pad_layer = nn.SpatialReflectionPadding(padW, padW, padH, padH)\n",
    "            pad_layer = set_datatype(pad_layer, params.gpu)\n",
    "            net:add(pad_layer)\n",
    "            layer.padW = 0\n",
    "            layer.padH = 0\n",
    "        end\n",
    "        net:add(layer)\n",
    "        if opt_targets[layer_name] then\n",
    "            loss_modules[layer_name] = {}\n",
    "            for loss_layer, args in pairs(opt_targets[layer_name]) do\n",
    "                if loss_layer == 'GramMSEDilation' then\n",
    "                    args['conv_layer'] = net.modules[#net.modules-1]\n",
    "                    local dilation_losses = get_loss_module(loss_layer, args)\n",
    "                    for i, dl in ipairs(dilation_losses) do \n",
    "                        dl = set_datatype(dl, params.gpu)\n",
    "                        table.insert(net.modules, #net.modules-1, dl)\n",
    "                    end\n",
    "                    loss_modules[layer_name][loss_layer] = dilation_losses\n",
    "                else\n",
    "                    local loss_module = get_loss_module(loss_layer, args)\n",
    "                    loss_module = set_datatype(loss_module, params.gpu)\n",
    "                    net:add(loss_module)\n",
    "                    loss_modules[layer_name][loss_layer] = loss_module\n",
    "                end\n",
    "            end\n",
    "            next_layer_ndx = next_layer_ndx + 1\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- Get flat list of loss modules to call in feval\n",
    "loss_modules_flat = {}\n",
    "for layer_name, layer_table in pairs(loss_modules) do\n",
    "    for loss_layer, loss_module in pairs(layer_table) do\n",
    "        if loss_layer == 'GramMSEDilation' then\n",
    "            for _, dilation_module in pairs(loss_module) do\n",
    "                loss_modules_flat[#loss_modules_flat + 1] = dilation_module\n",
    "            end\n",
    "        else\n",
    "            loss_modules_flat[#loss_modules_flat + 1] = loss_module\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- We don't need the base CNN anymore, so clean it up to save memory.\n",
    "cnn = nil\n",
    "for i=1, #net.modules do\n",
    "    local module = net.modules[i]\n",
    "    if torch.type(module) == 'nn.SpatialConvolutionMM' then\n",
    "        module.gradWeight = nil\n",
    "        module.gradBias = nil\n",
    "    end\n",
    "end\n",
    "collectgarbage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- Load initialisation \n",
    "local f = hdf5.open(params.init_file, 'r')\n",
    "img = f:all()['init']\n",
    "f:close()\n",
    "img = set_datatype(img, params.gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- Load mask if specified\n",
    "mask = nil\n",
    "if params.mask_file ~= 'path/to/HDF5file' then\n",
    "    local f = hdf5.open(params.mask_file, 'r')\n",
    "    mask = f:all()['mask']\n",
    "    f:close()\n",
    "    mask = set_datatype(mask, params.gpu)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- Run it through the network once to get the proper size for the gradient\n",
    "-- All the gradients will come from the extra loss modules, so we just pass\n",
    "-- zeros into the top of the net on the backward pass.\n",
    "y = net:forward(img)\n",
    "dy = img.new(#y):zero()\n",
    "\n",
    "-- Declare optimisation options\n",
    "optim_state = {\n",
    "  maxIter = params.max_iter,\n",
    "  verbose = true,\n",
    "  tolX = 0,\n",
    "  tolFun = 0,\n",
    "}\n",
    "\n",
    "-- Get layer_order for use in maybe_print\n",
    "layer_order = params.layer_order:split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- Function to evaluate loss and gradient. We run the net forward and\n",
    "-- backward to get the gradient, and sum up losses from the loss modules.\n",
    "-- optim.lbfgs internally handles iteration and calls this fucntion many\n",
    "-- times, so we manually count the number of iterations to handle printing\n",
    "-- and saving intermediate results.\n",
    "num_calls = 0\n",
    "function feval(x)\n",
    "    num_calls = num_calls + 1\n",
    "    net:forward(x)\n",
    "    local grad = net:updateGradInput(x, dy)\n",
    "    local loss = 0\n",
    "    for _, mod in ipairs(loss_modules_flat) do\n",
    "        loss = loss + mod.loss\n",
    "    end\n",
    "    maybe_print(num_calls, params.print_iter, params.max_iter, layer_order, loss_modules, loss)\n",
    "    maybe_save(num_calls, params.save_iter, params.max_iter, params.output_file, img)\n",
    "\n",
    "    if mask then\n",
    "        grad[mask:repeatTensor(1,1,1):expandAs(grad)] = 0\n",
    "    end\n",
    "\n",
    "    collectgarbage()\n",
    "    -- optim.lbfgs expects a vector for gradients\n",
    "    return loss, grad:view(grad:nElement())\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Running optimization with L-BFGS\t\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<optim.lbfgs> \tcreating recyclable direction/step/history buffers\t\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Iteration 50 / 50\t\n",
       "relu1_1\t\n",
       "GramMSE loss: 43328.506470\t\n",
       "relu2_1\t\n",
       "GramMSE loss: 313642.517090\t\n",
       "relu3_1\t\n",
       "GramMSE loss: 90680.923462\t\n",
       "relu4_1\t\n",
       "GramMSE loss: 509457.916260\t\n",
       "relu5_1\t\n",
       "GramMSE loss: 6963.839531\t\n",
       "relu4_2\t\n",
       "MSE loss: 369163.031250\t\n",
       "Total loss: 1333236.734062\t\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<optim.lbfgs> \treached max number of iterations\t\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " -- Run optimization.\n",
    "print('Running optimization with L-BFGS')\n",
    "local x, losses = optim.lbfgs(feval, img, optim_state)\n",
    "\n",
    "-- Also save result if optimisation stops before max iter is reached\n",
    "if num_calls < params.max_iter then\n",
    "    maybe_save(params.max_iter, params.save_iter, params.max_iter, params.output_file, img)\n",
    "end\n",
    "\n",
    "-- Optionally save the loss as tracked over the optimisation\n",
    "if params.loss_file ~= 'path/to/HDF5file' then\n",
    "    local f = hdf5.open(params.loss_file, 'w')\n",
    "    f:write('losses', torch.Tensor(losses):double())\n",
    "    f:close()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\t\n",
       "\u001b[1;35mlbfgs(opfunc, x[, config][, state])\u001b[0m\n",
       "\n",
       "\n",
       "An implementation of \u001b[1;30mL-BFGS\u001b[0m that relies on a user-provided line search \n",
       "function (\u001b[0;32m state.lineSearch \u001b[0m).\n",
       "If this function is not provided, then a simple learning rate is used \n",
       "to produce fixed size steps.\n",
       "Fixed size steps are much less costly than line searches, and can be useful \n",
       "for stochastic problems.\n",
       "\n",
       "The learning rate is used even when a line search is provided.\n",
       "This is also useful for large-scale stochastic problems, where opfunc \n",
       "is a noisy approximation of\u001b[0;32m f(x) \u001b[0m.\n",
       "In that case, the learning rate allows a reduction of confidence in the \n",
       "step size.\n",
       "\n",
       "Arguments:\n",
       "\n",
       "\u001b[0;34m> \u001b[0m\u001b[0;32m opfunc \u001b[0m: a function that takes a single input\u001b[0;32m X \u001b[0m, the point of \n",
       "evaluation, and returns\u001b[0;32m f(X) \u001b[0mand\u001b[0;32m df/dX \u001b[0m\u001b[0;34m> \u001b[0m\u001b[0;32m x \u001b[0m: the initial point\n",
       "\u001b[0;34m> \u001b[0m\u001b[0;32m config \u001b[0m: a table with configuration parameters for the optimizer\n",
       "\u001b[0;34m> \u001b[0m\u001b[0;32m config.maxIter \u001b[0m: Maximum number of iterations allowed\n",
       "\u001b[0;34m> \u001b[0m\u001b[0;32m config.maxEval \u001b[0m: Maximum number of function evaluations\n",
       "\u001b[0;34m> \u001b[0m\u001b[0;32m config.tolFun \u001b[0m: Termination tolerance on the first-order optimality\n",
       "\u001b[0;34m> \u001b[0m\u001b[0;32m config.tolX \u001b[0m: Termination tol on progress in terms of func/param \n",
       "changes\n",
       "\u001b[0;34m> \u001b[0m\u001b[0;32m config.lineSearch \u001b[0m: A line search function\n",
       "\u001b[0;34m> \u001b[0m\u001b[0;32m config.learningRate \u001b[0m: If no line search provided, then a fixed \n",
       "step size is used\n",
       "\n",
       "\n",
       "Returns:\n",
       "\n",
       "\u001b[0;34m> \u001b[0m\u001b[0;32m x* \u001b[0m: the new\u001b[0;32m x \u001b[0mvector, at the optimal point\n",
       "\u001b[0;34m> \u001b[0m\u001b[0;32m f \u001b[0m: a table of all function values:\n",
       "<ul>\n",
       "<li>\u001b[0;32m f[1] \u001b[0mis the value of the function before any optimization and\n",
       "\u001b[0;34m> \u001b[0m\u001b[0;32m f[#f] \u001b[0mis the final fully optimized value, at\u001b[0;32m x* \u001b[0m</li>\n",
       "</ul>\t\n",
       "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\t\n",
       "\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?optim.lbfgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
